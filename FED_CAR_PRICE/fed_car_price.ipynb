{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxQs85PH9_up"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUjV6u7MLg6T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:19.266572Z",
          "iopub.status.busy": "2025-03-03T09:13:19.266195Z",
          "iopub.status.idle": "2025-03-03T09:13:24.185712Z",
          "shell.execute_reply": "2025-03-03T09:13:24.183787Z",
          "shell.execute_reply.started": "2025-03-03T09:13:19.266542Z"
        },
        "id": "gIcEskgmLg6W",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# !pip install --upgrade ipykernel\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "\n",
        "path_to_data = r\"car_price_dataset.csv\"\n",
        "\n",
        "data = pd.read_csv(path_to_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:24.188628Z",
          "iopub.status.busy": "2025-03-03T09:13:24.18788Z",
          "iopub.status.idle": "2025-03-03T09:13:24.213395Z",
          "shell.execute_reply": "2025-03-03T09:13:24.211461Z",
          "shell.execute_reply.started": "2025-03-03T09:13:24.188575Z"
        },
        "id": "C0hFujJXLg6X",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "print(data.dtypes)\n",
        "\n",
        "x =  np.where(data.dtypes.to_numpy() == np.dtype('int64'))\n",
        "y = np.where(data.dtypes.to_numpy() == np.dtype('float64'))\n",
        "\n",
        "numeric_cols_idx = np.concatenate((x[0],y[0]))\n",
        "print(numeric_cols_idx)\n",
        "numeric_cols = data.columns[numeric_cols_idx]\n",
        "\n",
        "print(numeric_cols)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(data[numeric_cols])\n",
        "\n",
        "# print(data.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:24.215778Z",
          "iopub.status.busy": "2025-03-03T09:13:24.215393Z",
          "iopub.status.idle": "2025-03-03T09:13:24.25119Z",
          "shell.execute_reply": "2025-03-03T09:13:24.249461Z",
          "shell.execute_reply.started": "2025-03-03T09:13:24.215738Z"
        },
        "id": "wx679LeOLg6X",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data[numeric_cols] = scaler.transform(data[numeric_cols])\n",
        "print(data)\n",
        "np_data = data.to_numpy()\n",
        "\n",
        "print(np_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:24.253099Z",
          "iopub.status.busy": "2025-03-03T09:13:24.252732Z",
          "iopub.status.idle": "2025-03-03T09:13:24.261298Z",
          "shell.execute_reply": "2025-03-03T09:13:24.258965Z",
          "shell.execute_reply.started": "2025-03-03T09:13:24.25303Z"
        },
        "id": "3hg7vWDVLg6X",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "categoric_cols_idx = np.where(data.dtypes.to_numpy() == np.dtype('object'))[0]\n",
        "categoric_cols = data.columns[categoric_cols_idx]\n",
        "print(categoric_cols, categoric_cols_idx)\n",
        "encoders = [LabelEncoder() for _ in range(len(categoric_cols))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:24.263836Z",
          "iopub.status.busy": "2025-03-03T09:13:24.263447Z",
          "iopub.status.idle": "2025-03-03T09:13:24.308358Z",
          "shell.execute_reply": "2025-03-03T09:13:24.306138Z",
          "shell.execute_reply.started": "2025-03-03T09:13:24.263798Z"
        },
        "id": "o-UkenmbLg6Y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for i in range(len(categoric_cols)):\n",
        "    encoders[i].fit(data[categoric_cols[i]])\n",
        "    data[categoric_cols[i]] = encoders[i].transform(data[categoric_cols[i]])\n",
        "\n",
        "# data[categoric_cols] = data[categoric_cols].apply(lambda x: data[x.name].fit_transform(x))\n",
        "print(data[categoric_cols])\n",
        "\n",
        "BRAND_EMBED, MODEL_EMBED, FUEL_EMBED, TRANSMISSION_EMBED = (data[categoric_cols].apply(np.max)+1).to_numpy()\n",
        "print(BRAND_EMBED, MODEL_EMBED, FUEL_EMBED, TRANSMISSION_EMBED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:24.309747Z",
          "iopub.status.busy": "2025-03-03T09:13:24.309388Z",
          "iopub.status.idle": "2025-03-03T09:13:24.333113Z",
          "shell.execute_reply": "2025-03-03T09:13:24.331615Z",
          "shell.execute_reply.started": "2025-03-03T09:13:24.309715Z"
        },
        "id": "rG25MQnxLg6Y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "INPUT_SIZE = 256\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "CAT_COLS_IDX = categoric_cols_idx\n",
        "EMBEDDING_SIZE = 4\n",
        "\n",
        "EPOCHS = 100\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, data, numeric_cols, categoric_cols):\n",
        "        self.numeric_data = torch.tensor(data[numeric_cols[:-1]].to_numpy(), dtype = torch.float32)\n",
        "        self.categoric_data = torch.tensor(data[categoric_cols].to_numpy())\n",
        "        self.price = torch.tensor(data['Price'].to_numpy(), dtype = torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.price)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        num_features = self.numeric_data[idx]\n",
        "        cat_features = self.categoric_data[idx]\n",
        "        price = self.price[idx]\n",
        "        return num_features, cat_features, price\n",
        "\n",
        "def collate_fn(batch):\n",
        "    num_batch = torch.stack([item[0] for item in batch])\n",
        "    cat_batch = torch.stack([item[1] for item in batch])\n",
        "    prices = torch.stack([item[2] for item in batch])\n",
        "    return num_batch, cat_batch, prices\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.ln1 = nn.Linear(4*4 + 5, INPUT_SIZE//2)\n",
        "        self.ln2 = nn.Linear(INPUT_SIZE//2, INPUT_SIZE//4)\n",
        "        self.out = nn.Linear(INPUT_SIZE//4, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        embed_list = [BRAND_EMBED, MODEL_EMBED, FUEL_EMBED, TRANSMISSION_EMBED]\n",
        "\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(i, EMBEDDING_SIZE) for i in embed_list])\n",
        "\n",
        "    def forward(self, num, cat) -> torch.Tensor:\n",
        "        num = num.to(DEVICE)\n",
        "        cat = cat.to(DEVICE)\n",
        "\n",
        "        embeds = [self.embeddings[i](cat[:, i]) for i in range(len(CAT_COLS_IDX))]\n",
        "        embed = torch.cat(embeds, dim=1)\n",
        "\n",
        "        x = torch.cat((embed, num), dim=1)\n",
        "        return self.out(self.relu(self.ln2(self.relu(self.ln1(x)))))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def train(net: Net, trainloader, epochs = EPOCHS):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr = 0.01)\n",
        "    losses = []\n",
        "    for _ in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for num_batch, cat_batch, price_batch in trainloader:\n",
        "            num_batch = num_batch.to(DEVICE)\n",
        "            cat_batch = cat_batch.to(DEVICE)\n",
        "            price_batch = price_batch.to(DEVICE)\n",
        "            # print(cat_batch, cat_batch.shape)\n",
        "            optimizer.zero_grad()\n",
        "            y_out = net(num_batch, cat_batch).squeeze(1)\n",
        "            # print(y_out.shape, price_batch.shape)\n",
        "            loss = criterion(y_out, price_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss+= loss.item()\n",
        "        epoch_loss/= len(trainloader.dataset)\n",
        "        losses.append(epoch_loss)\n",
        "        if(_%10==0):\n",
        "            print(f\"EPOCH: {_}, LOSS: {epoch_loss}\")\n",
        "    plt.plot(losses)\n",
        "    plt.show()\n",
        "\n",
        "def flwr_train(net: Net, trainloader, epochs = EPOCHS):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr = 0.01)\n",
        "    losses = []\n",
        "    for _ in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for num_batch, cat_batch, price_batch in trainloader:\n",
        "            num_batch = num_batch.to(DEVICE)\n",
        "            cat_batch = cat_batch.to(DEVICE)\n",
        "            price_batch = price_batch.to(DEVICE)\n",
        "            # print(cat_batch, cat_batch.shape)\n",
        "            optimizer.zero_grad()\n",
        "            y_out = net(num_batch, cat_batch).squeeze(1)\n",
        "            # print(y_out.shape, price_batch.shape)\n",
        "            loss = criterion(y_out, price_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss+= loss.item()\n",
        "        epoch_loss/= len(trainloader.dataset)\n",
        "        losses.append(epoch_loss)\n",
        "        if(_%10==0):\n",
        "            print(f\"EPOCH: {_}, LOSS: {epoch_loss}\")\n",
        "\n",
        "def test(net: Net, testloader):\n",
        "    criterion = nn.MSELoss()\n",
        "    net.train()\n",
        "    tot_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for num_batch, cat_batch, price_batch in testloader:\n",
        "            num_batch = num_batch.to(DEVICE)\n",
        "            cat_batch = cat_batch.to(DEVICE)\n",
        "            price_batch = price_batch.to(DEVICE)\n",
        "            y_out = net(num_batch, cat_batch).squeeze(1)\n",
        "            loss = criterion(y_out, price_batch)\n",
        "            tot_loss += loss.item()\n",
        "    tot_loss/=len(testloader.dataset)\n",
        "    return tot_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:24.334527Z",
          "iopub.status.busy": "2025-03-03T09:13:24.334207Z",
          "iopub.status.idle": "2025-03-03T09:13:24.38023Z",
          "shell.execute_reply": "2025-03-03T09:13:24.378464Z",
          "shell.execute_reply.started": "2025-03-03T09:13:24.334495Z"
        },
        "id": "Kbx_vSNULg6Z",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size = 0.1 )\n",
        "\n",
        "\n",
        "# print(test_data, train_data)\n",
        "# print(len(test_data), len(train_data))\n",
        "full_dataset = dataset(data, numeric_cols, categoric_cols)\n",
        "train_dataset = dataset(train_data, numeric_cols, categoric_cols)\n",
        "test_dataset = dataset(test_data, numeric_cols, categoric_cols)\n",
        "\n",
        "trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:24.384698Z",
          "iopub.status.busy": "2025-03-03T09:13:24.384339Z",
          "iopub.status.idle": "2025-03-03T09:13:24.396294Z",
          "shell.execute_reply": "2025-03-03T09:13:24.39518Z",
          "shell.execute_reply.started": "2025-03-03T09:13:24.384664Z"
        },
        "id": "v2k2bwckLg6Z",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# x = next(iter(trainloader))\n",
        "\n",
        "# criterion = nn.MSELoss()\n",
        "# optimizer = torch.optim.Adam(net.parameters())\n",
        "# for i in range(100):\n",
        "#     num, cat, price = x[0][0],x[1][0], x[2][0]\n",
        "#     out = net(num, cat).squeeze(0)\n",
        "#     optimizer.zero_grad()\n",
        "#     loss = criterion(out, price)\n",
        "#     if(i%10==0):\n",
        "#         print(\"out: \", out, \"price: \", price, \"loss: \",loss)\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "net = Net()\n",
        "net = net.to(DEVICE)\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:24.398429Z",
          "iopub.status.busy": "2025-03-03T09:13:24.397954Z",
          "iopub.status.idle": "2025-03-03T09:13:24.424661Z",
          "shell.execute_reply": "2025-03-03T09:13:24.423283Z",
          "shell.execute_reply.started": "2025-03-03T09:13:24.398387Z"
        },
        "id": "urRhk3mpLg6Z",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "num_batch, cat_batch, price_batch = next(iter(trainloader))\n",
        "\n",
        "# print(num_batch, num_batch.shape )\n",
        "# print(cat_batch, cat_batch.shape )\n",
        "# print(price_batch, price_batch.shape )\n",
        "\n",
        "# brand_embed = nn.Embedding(BRAND_EMBED, 10)\n",
        "# model_embed = nn.Embedding(MODEL_EMBED, 10)\n",
        "# fuel_embed = nn.Embedding(FUEL_EMBED, 10)\n",
        "# transmission_embed = nn.Embedding(TRANSMISSION_EMBED, 10)\n",
        "\n",
        "# embeddings = nn.ModuleList( [brand_embed, model_embed, fuel_embed, transmission_embed] )\n",
        "\n",
        "# embed = torch.tensor([])\n",
        "\n",
        "# for i in range(len(CAT_COLS_IDX)):\n",
        "#     embed = torch.concat((embed, embeddings[i](cat_batch[:, i]),))\n",
        "# print(embed, embed.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:24.42664Z",
          "iopub.status.busy": "2025-03-03T09:13:24.426335Z",
          "iopub.status.idle": "2025-03-03T09:13:44.213377Z",
          "shell.execute_reply": "2025-03-03T09:13:44.211436Z",
          "shell.execute_reply.started": "2025-03-03T09:13:24.426609Z"
        },
        "id": "QL_SWqKnLg6a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train(net, trainloader, epochs = 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:44.215195Z",
          "iopub.status.busy": "2025-03-03T09:13:44.21479Z",
          "iopub.status.idle": "2025-03-03T09:13:44.252095Z",
          "shell.execute_reply": "2025-03-03T09:13:44.250931Z",
          "shell.execute_reply.started": "2025-03-03T09:13:44.215162Z"
        },
        "id": "gTPoHN8uLg6a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(\"TEST LOSS: \", test(net, testloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:44.253393Z",
          "iopub.status.busy": "2025-03-03T09:13:44.253081Z",
          "iopub.status.idle": "2025-03-03T09:13:48.257854Z",
          "shell.execute_reply": "2025-03-03T09:13:48.255833Z",
          "shell.execute_reply.started": "2025-03-03T09:13:44.253364Z"
        },
        "id": "gbDAJ6gELg6a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install flwr[simulation]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:48.263176Z",
          "iopub.status.busy": "2025-03-03T09:13:48.261525Z",
          "iopub.status.idle": "2025-03-03T09:13:52.354852Z",
          "shell.execute_reply": "2025-03-03T09:13:52.353514Z",
          "shell.execute_reply.started": "2025-03-03T09:13:48.263099Z"
        },
        "id": "ZJyr1_53Lg6a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# pip install flwr-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:52.35637Z",
          "iopub.status.busy": "2025-03-03T09:13:52.356077Z",
          "iopub.status.idle": "2025-03-03T09:13:52.365591Z",
          "shell.execute_reply": "2025-03-03T09:13:52.364458Z",
          "shell.execute_reply.started": "2025-03-03T09:13:52.356342Z"
        },
        "id": "q0KLsXSXLg6a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from flwr_datasets.partitioner import IidPartitioner\n",
        "from datasets import Dataset as HFdataset\n",
        "from torch.utils.data import Subset\n",
        "import sklearn\n",
        "NUM_CLIENTS = 5\n",
        "\n",
        "class Federated_Dataset():\n",
        "    def __init__(self, dataset, num_client = NUM_CLIENTS):\n",
        "        self.data_per_client = len(dataset) // num_client\n",
        "        self.indices = np.random.permutation(len(dataset))\n",
        "        self.dataset = dataset\n",
        "        self.partitioned_dataset = []\n",
        "        for i in range(num_client):\n",
        "            self.partitioned_dataset.append(Subset(dataset, self.indices[i*self.data_per_client: (i+1)*self.data_per_client]))\n",
        "    def load_partition(self, partition_id: int):\n",
        "        return self.partitioned_dataset[partition_id]\n",
        "\n",
        "def partition_dataset(dataset, num_client = NUM_CLIENTS):\n",
        "    data_per_client = len(dataset) // num_client\n",
        "    indices = np.random.permutation(len(dataset))\n",
        "    partitioned_dataset = []\n",
        "    for i in range(num_client):\n",
        "        partitioned_dataset.append(Subset(dataset, indices[i*data_per_client: (i+1)*data_per_client]))\n",
        "        print(partitioned_dataset[i].__len__())\n",
        "    print(partitioned_dataset)\n",
        "    return partitioned_dataset\n",
        "\n",
        "def load_datasets(fds: Federated_Dataset, partition_id: int):\n",
        "    partition = fds.load_partition(partition_id)\n",
        "    train_partition, test_partition = sklearn.model_selection.train_test_split(partition, test_size = 0.1)\n",
        "    fds_trainloader = DataLoader(train_partition, batch_size = BATCH_SIZE, shuffle = True)\n",
        "    fds_testloader = DataLoader(test_partition, batch_size = BATCH_SIZE, shuffle = False)\n",
        "    return fds_trainloader, fds_testloader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:52.367281Z",
          "iopub.status.busy": "2025-03-03T09:13:52.366434Z",
          "iopub.status.idle": "2025-03-03T09:13:52.418752Z",
          "shell.execute_reply": "2025-03-03T09:13:52.417512Z",
          "shell.execute_reply.started": "2025-03-03T09:13:52.367185Z"
        },
        "id": "uRqWW0kXLg6b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "fds = Federated_Dataset(full_dataset, num_client = NUM_CLIENTS)\n",
        "part_0= fds.load_partition(partition_id = 0)\n",
        "\n",
        "part0_trainloader, part0_testloader =  load_datasets(fds, 0)\n",
        "# print(next(iter(part0_trainloader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:52.420631Z",
          "iopub.status.busy": "2025-03-03T09:13:52.420235Z",
          "iopub.status.idle": "2025-03-03T09:13:52.429145Z",
          "shell.execute_reply": "2025-03-03T09:13:52.427639Z",
          "shell.execute_reply.started": "2025-03-03T09:13:52.420593Z"
        },
        "id": "hmRCRr6xLg6b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "def set_parameters(net, parameters):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def get_parameters(net):\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:52.430923Z",
          "iopub.status.busy": "2025-03-03T09:13:52.430551Z",
          "iopub.status.idle": "2025-03-03T09:13:52.463693Z",
          "shell.execute_reply": "2025-03-03T09:13:52.461741Z",
          "shell.execute_reply.started": "2025-03-03T09:13:52.430882Z"
        },
        "id": "55Z6jXoXLg6b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from flwr.client import NumPyClient, Client, ClientApp\n",
        "from flwr.common import Context\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.client import NumPyClient, Client, ClientApp\n",
        "from flwr.common import Context\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "\n",
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self, partition_id, net,  trainloader, testloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.partition_id = partition_id\n",
        "\n",
        "    def set_params(self, parameters):\n",
        "        params_dict = zip(self.net.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "        self.net.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    def get_params(self, config):\n",
        "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
        "        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n",
        "\n",
        "    def fit(self, params, config):\n",
        "        print(f\"[Client {self.partition_id}] ----Training----\")\n",
        "        self.set_params(params)\n",
        "        flwr_train(self.net, self.trainloader, epochs=30)\n",
        "        return self.get_params(self.net), len(self.trainloader.dataset), {}\n",
        "\n",
        "    def evaluate(self, params, config):\n",
        "        self.set_params(params)\n",
        "        loss = test(self.net, self.testloader)\n",
        "        print(f\"[Client {self.partition_id}] evaluate, Test_loss:{loss}\")\n",
        "        return loss, len(self.testloader.dataset), {'loss': loss}\n",
        "\n",
        "def client_fn(context: Context):\n",
        "    net = Net().to(DEVICE)\n",
        "    partition_id = context.node_config['partition-id']\n",
        "    print(\"NODE CONFIG: \", partition_id)\n",
        "    trainloader, testloader = load_datasets(fds, partition_id)\n",
        "    return FlowerClient(partition_id, net, trainloader, testloader).to_client()\n",
        "\n",
        "client = ClientApp(client_fn=client_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:52.465155Z",
          "iopub.status.busy": "2025-03-03T09:13:52.464802Z",
          "iopub.status.idle": "2025-03-03T09:13:52.492505Z",
          "shell.execute_reply": "2025-03-03T09:13:52.491005Z",
          "shell.execute_reply.started": "2025-03-03T09:13:52.465124Z"
        },
        "id": "VilUNae1Lg6b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "strategy = FedAvg(\n",
        "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "    fraction_evaluate=1,  # Sample 50% of available clients for evaluation\n",
        "    min_fit_clients=NUM_CLIENTS,  # Never sample less than 10 clients for training\n",
        "    min_evaluate_clients=NUM_CLIENTS,  # Never sample less than 5 clients for evaluation\n",
        "    min_available_clients=NUM_CLIENTS,  # Wait until all 10 clients are available\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:52.493737Z",
          "iopub.status.busy": "2025-03-03T09:13:52.493471Z",
          "iopub.status.idle": "2025-03-03T09:13:52.523302Z",
          "shell.execute_reply": "2025-03-03T09:13:52.521926Z",
          "shell.execute_reply.started": "2025-03-03T09:13:52.493715Z"
        },
        "id": "NsYm66hfLg6b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def server_fn(context:Context):\n",
        "    config = ServerConfig(num_rounds = 3)\n",
        "    return ServerAppComponents(strategy = strategy, config = config)\n",
        "\n",
        "server = ServerApp(server_fn = server_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:52.524637Z",
          "iopub.status.busy": "2025-03-03T09:13:52.524295Z",
          "iopub.status.idle": "2025-03-03T09:13:52.54815Z",
          "shell.execute_reply": "2025-03-03T09:13:52.546499Z",
          "shell.execute_reply.started": "2025-03-03T09:13:52.524601Z"
        },
        "id": "xxpy1i-JLg6b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Specify the resources each of your clients need\n",
        "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
        "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
        "\n",
        "# When running on GPU, assign an entire GPU for each client\n",
        "if DEVICE == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
        "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
        "    # and how to set up the `backend_config`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-03T09:13:52.549342Z",
          "iopub.status.busy": "2025-03-03T09:13:52.549018Z",
          "iopub.status.idle": "2025-03-03T09:14:43.15824Z",
          "shell.execute_reply": "2025-03-03T09:14:43.157348Z",
          "shell.execute_reply.started": "2025-03-03T09:13:52.549313Z"
        },
        "id": "hA8Djgh9Lg6b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from flwr.simulation import run_simulation\n",
        "\n",
        "run_simulation(\n",
        "    server_app=server,\n",
        "    client_app=client,\n",
        "    num_supernodes=NUM_CLIENTS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPk-ug4xLg6b",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 6552734,
          "sourceId": 10587923,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}